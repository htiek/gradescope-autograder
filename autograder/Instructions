This is a general autograder framework for testing C++ assignments on GradeScope.

Here's what you need to do to configure everything:

1. SPECIFY A FILE MANIFEST. Edit the file MANIFEST to contain a list of all the files you expect
   students to submit. Those files will be extracted from the submission/ directory, and the
   autograder will report an error if any of them can't be found.
   
   The autograder is designed to work in cases where students might submit the wrong directory
   or be up or down the directory hierarchy a little bit. As a result, you just need to specify
   the name of the file, not the path to it. The autograder will recursively traverse the
   submissions directory to try to find everything.
   
   Recommendation: Only include files in MANIFEST that you expect students to actually edit. You
   can leave a clean copy of the starter files in the build directory.
   
2. SET UP DEFAULT FILES. If you would like, you may set up the default-files directory to contain
   default versions of each file to use in the event that a student forgets to submit some of the
   required files from the manifest. For each file named in the manifest, if that file is not
   present, the test driver will check the default-files/ directory for a file with the same name,
   then use that file instead. The autograder will then include a warning to the student that not
   all files were submitted.
   
   For C++ files, our recommendation is to have the fallback be a compilable version of each needed
   file that just has each function call abort() to fail all tests. For non-C++ files, we recommend
   making those files fail every test case.

3. SET UP THE BUILD DIRECTORY. You should include in build-directory/ enough files to make it
   possible to build all of the object files for the student code. This directory should build
   clean as-is. It will be built twice by the system: once during setup (to speed up build times
   when students submit) and once more after files are submitted (so that student code gets
   linked in properly).
   
   There's a default Makefile in the build directory that you're welcome to use. It just compiles
   all the .cpp files in the directory to object files.
   
   The autograder will build an executable that runs all of the tests you've provided by linking
   all the .o files that your build directory against the test driver. As a result, you should
   not build any files with a main() function in them, since that will result in a linker error
   when trying to assemble the tests.
   
   Additionally, the test driver will try linking against all the .o files in build-directory/,
   but not .o files in any subdirectories. If that's a problem, let me know and I can adapt the
   system.
   
4. SET UP THE TESTS DIRECTORY. Create all the files you'd like to use to run tests in the tests/
   directory. You should define tests by using the TEST_GROUP and ADD_TEST commands from TestCase.h.
   The tests in this directory will be compiled and linked against all the object files from your
   build directory.
   
5. CONFIGURE YOUR SETUP SCRIPT. If you are writing pure C++ code that doesn't reference any external
   libraries, then you shouldn't need to do anything fancy here. However, if your autograder needs
   to use external libraries or tools, you may need to edit ./my-setup.sh to perform extra setup
   steps on the server when the autograder is uploaded.
   
6. (OPTIONALLY) CONFIGURE OUTPUT OPTIONS. The Gradescope autograder allows you to set some global
   options for the output, such as "only show this after the due date" or "forward stdout to the
   user." By default, we don't do any of these and just go with the defaults. To override this,
   add key/value pairs to the file output-config.json. Those key/value pairs will be copied over
   verbatim before the autograder fills in the fields. That way, if you try setting a property
   that's actually important (say, what the score is!), the autograder will take priority.
   
7. TEST YOUR SETUP! To confirm that your setup works, create a directory called submission/ and load
   it with whatever test submission you'd like. Then, invoke ./run_autograder to run the end-to-end
   pipeline and do whatever debugging or tuning you'd like.

8. GENERATE THE AUTOGRADER. The script ./assemble-autograder.sh will run an end-to-end test of the
   autograder to make sure that everything builds. It will then generate a .zip archive containing
   the autograder, which you can upload to GradeScope, and will report the total number of points
   possible for this assignment.
   
   In order to run this step, you have to load submission/ with a sample, valid student submission.
   It just needs to compile and doesn't have to pass any of the tests. This is required because
   otherwise the test build of the autograder will fail.
   
9. UPLOAD EVERYTHING! Go to GradeScope and upload the .zip archive generated by the assembler. When
   prompted for the point total, enter the value produced by the script.
